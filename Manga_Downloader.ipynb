{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahiaML/Manga-Downloader/blob/main/Manga_Downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill in the info in the cell below\n",
        "\n",
        "## Notes:\n",
        "1. If you want to run the script on colab you have to set folder_path = r\"/content\".\n",
        "2. If you want to download only 1 chapter, you have to set the chapter number in both start_from_chapter_num and stop_at_chapter_chapter_num."
      ],
      "metadata": {
        "id": "y-FF2RS2VSCU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CiMvRiwdTv5x"
      },
      "outputs": [],
      "source": [
        "# ----------  Insert the info  -----------#\n",
        "\n",
        "# Insert the name of the manga/manhwa you want\n",
        "Manga_name = \"Example_Example\"\n",
        "\n",
        "\n",
        "# Insert one the chapters links of the manga/manhwa you want to download from any of these two sites:\n",
        "# English: https://mangaonline.team/\n",
        "# Arabic: https://azoranov.com/\n",
        "url = \"https://mangaonline.team/manga/solo-leveling/chapter-2/\"\n",
        "\n",
        "\n",
        "# Insert the folder path in which you want to save the downloaded mange/manhwa\n",
        "#### PLEASE DON'T REMOVE THE r THAT IS FOUND BEFORE THE FOLDER PATH ####\n",
        "folder_path = r\"D:\\folder_name\\folder_name\\folder_name\" #### PLEASE DON'T REMOVE THE r THAT IS FOUND BEFORE THE FOLDER PATH ####\n",
        "\n",
        "# You can use this version if you are going to run the script on colab\n",
        "#folder_path = r\"/content\" #### PLEASE DON'T REMOVE THE r THAT IS FOUND BEFORE THE FOLDER PATH ####\n",
        "\n",
        "# Please indicate the chapter number from which you would like to begin downloading.\n",
        "start_from_chapter_num = 1\n",
        "\n",
        "# Please indicate the chapter number at which you would like to stop downloading.\n",
        "stop_at_chapter_chapter_num = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping script\n",
        "\n",
        "## Press control + F9 to start"
      ],
      "metadata": {
        "id": "8MI7PQr9Vbhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gREqhRFETv5v",
        "outputId": "f110561a-34e7-4cb1-88f4-3eab2512c224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.3.1)\n"
          ]
        }
      ],
      "source": [
        "#Install required libraries\n",
        "!pip install PyPDF2\n",
        "!pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jFgc0hI4Tv5x"
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "from bs4 import *\n",
        "import requests\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import os\n",
        "from io import BytesIO\n",
        "from PyPDF2 import PdfMerger \n",
        "from natsort import natsorted \n",
        "import shutil\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja_giMCbTv5y",
        "outputId": "d0b35901-f43f-4330-c2fa-993a710dc3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 50 Image Found!\n",
            "All Images Downloaded!\n",
            "Total 48 Image Found!\n",
            "All Images Downloaded!\n"
          ]
        }
      ],
      "source": [
        "# ----------  Download chapters images  -----------#\n",
        "\n",
        "urls, folders_names = [], []\n",
        "\n",
        "for i in range(start_from_chapter_num, stop_at_chapter_chapter_num+1):\n",
        "\turls.append(re.sub(\"\\d+/$\",\"{}/\",url).format(i))\n",
        "\tfolders_names.append(Manga_name + \" {}\".format(i))\n",
        "\n",
        "for url,folder_name in zip(urls,folders_names):\n",
        "\t\t# CREATE FOLDER\n",
        "\t\tdef folder_create(images,folder_name):\n",
        "\t\t\ttry:\n",
        "\t\t\t\t# folder creation\n",
        "\t\t\t\tfolder_name = folder_path.replace(\"\\\\\", \"/\") + \"/\" +folder_name\n",
        "\t\t\t\tos.mkdir(folder_name)\n",
        "\t\t\n",
        "\t\t\t# if folder exists with that name, ask another name\n",
        "\t\t\texcept:\n",
        "\t\t\t\tprint(\"Folder Exist with that name!\")\n",
        "\t\t\t\tfolder_create()\n",
        "\t\t\n",
        "\t\t\t# image downloading start\n",
        "\t\t\tdownload_images(images, folder_name)\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t# DOWNLOAD ALL IMAGES FROM THAT URL\n",
        "\t\tdef download_images(images, folder_name):\n",
        "\t\t\n",
        "\t\t\t# initial count is zero\n",
        "\t\t\tcount = 0\n",
        "\t\t\n",
        "\t\t\t# print total images found in URL\n",
        "\t\t\tprint(f\"Total {len(images)} Image Found!\")\n",
        "\t\t\n",
        "\t\t\t# checking if images is not zero\n",
        "\t\t\tif len(images) != 0:\n",
        "\t\t\t\tfor i, image in enumerate(images):\n",
        "\t\t\t\t\t# From image tag ,Fetch image Source URL\n",
        "\t\t\n",
        "\t\t\t\t\t\t\t\t# 1.data-srcset\n",
        "\t\t\t\t\t\t\t\t# 2.data-src\n",
        "\t\t\t\t\t\t\t\t# 3.data-fallback-src\n",
        "\t\t\t\t\t\t\t\t# 4.src\n",
        "\t\t\n",
        "\t\t\t\t\t# Here we will use exception handling\n",
        "\t\t\n",
        "\t\t\t\t\t# first we will search for \"data-srcset\" in img tag\n",
        "\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\t# In image tag ,searching for \"data-srcset\"\n",
        "\t\t\t\t\t\timage_link = image[\"data-srcset\"]\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t# then we will search for \"data-src\" in img\n",
        "\t\t\t\t\t# tag and so on..\n",
        "\t\t\t\t\texcept:\n",
        "\t\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\t\t# In image tag ,searching for \"data-src\"\n",
        "\t\t\t\t\t\t\timage_link = image[\"data-src\"]\n",
        "\t\t\t\t\t\texcept:\n",
        "\t\t\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\t\t\t# In image tag ,searching for \"data-fallback-src\"\n",
        "\t\t\t\t\t\t\t\timage_link = image[\"data-fallback-src\"]\n",
        "\t\t\t\t\t\t\texcept:\n",
        "\t\t\t\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\t\t\t\t# In image tag ,searching for \"src\"\n",
        "\t\t\t\t\t\t\t\t\timage_link = image[\"src\"]\n",
        "\t\t\n",
        "\t\t\t\t\t\t\t\t# if no Source URL found\n",
        "\t\t\t\t\t\t\t\texcept:\n",
        "\t\t\t\t\t\t\t\t\tpass\n",
        "\t\t\t\t\t\t\t\t\n",
        "\t\t\t\t\t# After getting Image Source URL\n",
        "\t\t\t\t\t# We will try to get the content of image\n",
        "\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\tr = requests.get(image_link).content\n",
        "\t\t\t\t\t\ttry:\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t# possibility of decode\n",
        "\t\t\t\t\t\t\tr = str(r, 'utf-8')\n",
        "\t\t\n",
        "\t\t\t\t\t\texcept UnicodeDecodeError:\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t\t# After checking above condition, Image Download start\n",
        "\t\t\t\t\t\t\twith open(f\"{folder_name}/images{i+1}.jpg\", \"wb+\") as f:\n",
        "\t\t\t\t\t\t\t\tf.write(r)\n",
        "\t\t\n",
        "\t\t\t\t\t\t\t# counting number of image downloaded\n",
        "\t\t\t\t\t\t\tcount += 1\n",
        "\t\t\t\t\texcept:\n",
        "\t\t\t\t\t\tpass\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# There might be possible, that all\n",
        "\t\t\t\t# images not download\n",
        "\t\t\t\t# if all images download\n",
        "\t\t\t\tif count == len(images):\n",
        "\t\t\t\t\tprint(\"All Images Downloaded!\")\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# if all images not download\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tprint(f\"Total {count} Images Downloaded Out of {len(images)}\")\n",
        "\t\t\t\t\t\t\n",
        "\t\t# MAIN FUNCTION START\n",
        "\t\tdef main(url):\n",
        "\t\t\n",
        "\t\t\t# content of URL\n",
        "\t\t\tr = requests.get(url)\n",
        "\t\t\n",
        "\t\t\t# Parse HTML Code\n",
        "\t\t\tsoup = BeautifulSoup(r.text, 'html.parser')\n",
        "\t\t\n",
        "\t\t\t# find all images in URL\n",
        "\t\t\timages = soup.findAll('img')\n",
        "\t\t\n",
        "\t\t\t# Call folder create function\n",
        "\t\t\tfolder_create(images,folder_name)\n",
        "\t\t\n",
        "\t\t# CALL MAIN FUNCTION\n",
        "\t\tmain(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------  Convert images to PDF  -----------#\n",
        "\n",
        "download_dir = folder_path.replace(\"\\\\\", \"/\")\n",
        "\n",
        "for image_dir in natsorted([f for f in os.listdir(download_dir) if os.path.isdir(os.path.join(download_dir, f))]):\n",
        "    pdf_merger = PdfMerger()\n",
        "\n",
        "    for filename in natsorted(os.listdir(download_dir + \"/\" + image_dir)):       \n",
        "        \n",
        "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
        "            with Image.open(os.path.join(download_dir + \"/\" + image_dir + \"/\" + filename)) as im:\n",
        "                with BytesIO() as f:\n",
        "                    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "                    im.convert('RGB').save(f, format='pdf')\n",
        "                    pdf_merger.append(BytesIO(f.getvalue()))   \n",
        "             \n",
        "    pdf_merger.write(os.path.join(download_dir, image_dir + \".pdf\"))\n",
        "    shutil.rmtree(os.path.join(download_dir, image_dir), ignore_errors=True)\n",
        "    "
      ],
      "metadata": {
        "id": "ZXSZzebqUsFe"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "aview",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eec6b78456dd61c6a0894a924dc588c1c829113589f4c409b19b99d7ab7ace98"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}